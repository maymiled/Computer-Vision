{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "7a705d20",
      "metadata": {
        "id": "7a705d20"
      },
      "source": [
        "# Lab1 â€” PyTorch Foundations for Computer Vision\n",
        "\n",
        "**Course**: Deep Learning for Image Analysis\n",
        "\n",
        "**Class**: M2 IASD App  \n",
        "\n",
        "**Professor**: Mehyar MLAWEH\n",
        "\n",
        "---\n",
        "\n",
        "## Objectives\n",
        "By the end of this lab, you should be able to:\n",
        "\n",
        "- Understand how **neurons and layers** are implemented in PyTorch\n",
        "- Manipulate **tensors** and reason about shapes\n",
        "- Use **autograd** to compute gradients\n",
        "- Implement a **training loop** yourself\n",
        "- Connect theory (neurons, loss, backprop) to actual code\n",
        "\n",
        "âš ï¸ This notebook is **intentionally incomplete**.  \n",
        "Whenever you see **`# TODO`**, you are expected to write code."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e07470cd",
      "metadata": {
        "id": "e07470cd"
      },
      "source": [
        "\n",
        "**Deadline:** ðŸ—“ï¸ **Saturday, February 7th (23:59)**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "60119f3a",
      "metadata": {
        "id": "60119f3a"
      },
      "source": [
        "## ðŸ¤– A small (honest) note before you start\n",
        "\n",
        "Letâ€™s be real for a second.\n",
        "\n",
        " I know you **can use LLMs (ChatGPT, Copilot, Claude, etc.)** to help you with this lab.  \n",
        "And yes, **I use them too**, so donâ€™t worry ðŸ˜„\n",
        "\n",
        "ðŸ‘‰ **You are allowed to use AI tools.**  \n",
        "But hereâ€™s the deal:\n",
        "\n",
        "- Donâ€™t just **copyâ€“paste** code you donâ€™t understand  \n",
        "- Take time to **read, question, and modify** what the model gives you  \n",
        "- If you can solve a block **by yourself, without AI**, thatâ€™s excellent\n",
        "\n",
        "Remember:\n",
        "\n",
        "> AI can write code for you, but **only you can understand it** â€” and understanding is what matters for exams, projects, and real work.\n",
        "\n",
        "Use these tools **as assistants, not as replacements for thinking**.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ“š Useful documentation (highly recommended)\n",
        "\n",
        "You will often find answers faster (and more reliably) by checking the official documentation:\n",
        "\n",
        "- **PyTorch main documentation**  \n",
        "  https://pytorch.org/docs/stable/index.html\n",
        "\n",
        "- **PyTorch tensors**  \n",
        "  https://pytorch.org/docs/stable/tensors.html\n",
        "\n",
        "- **Neural network modules (`torch.nn`)**  \n",
        "  https://pytorch.org/docs/stable/nn.html\n",
        "\n",
        "- **Loss functions** (`BCEWithLogitsLoss`, CrossEntropy, etc.)  \n",
        "  https://pytorch.org/docs/stable/nn.html#loss-functions\n",
        "\n",
        "- **Optimizers** (`SGD`, `Adam`, â€¦)  \n",
        "  https://pytorch.org/docs/stable/optim.html\n",
        "\n",
        "If you learn how to **navigate the documentation**, you are already thinking like a real AI engineer ðŸ‘Œ\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f278eff5",
      "metadata": {
        "id": "f278eff5"
      },
      "source": [
        "## PART I"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de614322",
      "metadata": {
        "id": "de614322"
      },
      "source": [
        "## 0) Colab setup â€” GPU check\n",
        "\n",
        "**Instructions**\n",
        "1. In Colab: `Runtime â†’ Change runtime type to GPU T4`\n",
        "2. Select **GPU**\n",
        "3. Save and restart runtime\n",
        "\n",
        "Then run the cell below.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72e3ba23",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72e3ba23",
        "outputId": "9404808a-c95f-4f7e-f729-54fd27016d91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.9.0+cu126\n",
            "CUDA available: True\n",
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "print(\"PyTorch version:\", torch.__version__)\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "device = \"cuda\"\n",
        "print(\"Using device:\", device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fcc7ceb1",
      "metadata": {
        "id": "fcc7ceb1"
      },
      "source": [
        "## 1) Imports and reproducibility\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0ce2798",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0ce2798",
        "outputId": "71230c61-1442-439f-d260-586fefe296b2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7da518280510>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "torch.manual_seed(7)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9349f5a5",
      "metadata": {
        "id": "9349f5a5"
      },
      "source": [
        "## 2) PyTorch tensors and shapes\n",
        "\n",
        "Tensors are multi-dimensional arrays that support:\n",
        "- GPU acceleration\n",
        "- automatic differentiation\n",
        "\n",
        "Understanding **shapes** is critical in deep learning.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2998b3f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2998b3f",
        "outputId": "0c130746-47f4-493d-f780-82a62bb7e1a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a shape: torch.Size([3])\n",
            "b shape: torch.Size([4, 5])\n"
          ]
        }
      ],
      "source": [
        "# Examples\n",
        "a = torch.tensor([1.0, 2.0, 3.0])\n",
        "b = torch.randn(4, 5)\n",
        "\n",
        "print(\"a shape:\", a.shape)\n",
        "print(\"b shape:\", b.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d675977",
      "metadata": {
        "id": "0d675977"
      },
      "source": [
        "### ðŸ” Question (answer inside the markdown)\n",
        "- How many dimensions does tensor `b` have?\n",
        "- What does each dimension represent conceptually?\n",
        "\n",
        "Tensor b has 2 dimensions.\n",
        "The first dimension (4) represents rows/samples, and the second (5) represents columns/features."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ea0588f",
      "metadata": {
        "id": "9ea0588f"
      },
      "source": [
        "### âœ…Tensor operations\n",
        "\n",
        "Complete the following:\n",
        "\n",
        "1. Create a tensor `x` of shape `(8, 3)` with random values  \n",
        "2. Compute:\n",
        "   - the **mean of each column**\n",
        "   - the **L2 norm of each row**\n",
        "3. Normalize `x` **row-wise** using the L2 norm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4629e99",
      "metadata": {
        "id": "b4629e99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20badcc7-831b-4e00-a632-f57c0bf89db5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 3]) torch.Size([3]) torch.Size([8, 1]) torch.Size([8, 3])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# TODO: create x\n",
        "x = torch.randn(8, 3)\n",
        "\n",
        "# TODO: column mean\n",
        "col_mean = x.mean(dim=0)\n",
        "\n",
        "# TODO: row-wise L2 norm\n",
        "row_norm = torch.norm(x, p=2, dim=1, keepdim=True)\n",
        "\n",
        "# TODO: normalized tensor\n",
        "x_normalized = x / row_norm\n",
        "\n",
        "print(x.shape, col_mean.shape, row_norm.shape, x_normalized.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d0f8928",
      "metadata": {
        "id": "4d0f8928"
      },
      "source": [
        "## 3) Artificial neuron â€” from math to code\n",
        "\n",
        "A neuron computes:\n",
        "\n",
        "$$\n",
        "z = \\sum_i w_i x_i + b\n",
        "$$\n",
        "\n",
        "Then applies an activation function:\n",
        "\n",
        "$$\n",
        "y = g(z)\n",
        "$$\n",
        "\n",
        "This section connects directly to the theory seen in class.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d271c97",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6d271c97",
        "outputId": "bd6fa3b1-1cce-4b81-8d25-4951ed193e65"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-0.8000)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "x = torch.tensor([1.0, -2.0, 3.0])\n",
        "w = torch.tensor([0.2, 0.4, -0.1])\n",
        "b = torch.tensor(0.1)\n",
        "\n",
        "z = torch.sum(x * w) + b\n",
        "z\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db2d7490",
      "metadata": {
        "id": "db2d7490"
      },
      "source": [
        "### Activation functions\n",
        "\n",
        "1. Implement **ReLU**\n",
        "2. Implement **Sigmoid**\n",
        "3. Apply both to `z` and compare the outputs\n",
        "\n",
        "Which activation preserves negative values?\n",
        "Neither ReLU nor Sigmoid preserves negative values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f307df40",
      "metadata": {
        "id": "f307df40",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f677d31-12b5-4d42-b156-d37a26e1e71b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0.0000, 0.0000, 0.0000, 1.0056, 0.0000]),\n",
              " tensor([0.4807, 0.2845, 0.1308, 0.7322, 0.3330]))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# TODO\n",
        "def relu(z):\n",
        "    return torch.maximum(z, torch.tensor(0.0))\n",
        "\n",
        "def sigmoid(z):\n",
        "    return 1 / (1 + torch.exp(-z))\n",
        "\n",
        "# Example input\n",
        "z = torch.randn(5)\n",
        "\n",
        "y_relu = relu(z)\n",
        "y_sigmoid = sigmoid(z)\n",
        "\n",
        "y_relu, y_sigmoid\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e764019",
      "metadata": {
        "id": "8e764019"
      },
      "source": [
        "## 4) Autograd and gradients\n",
        "\n",
        "PyTorch uses **automatic differentiation** to compute gradients\n",
        "using the **chain rule** (backpropagation).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50f1aab4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50f1aab4",
        "outputId": "bf21f3ac-c2d8-4409-8f49-18c83394dc77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: 2.890000104904175\n",
            "grad w: tensor([-3.4000, -6.8000,  3.4000])\n",
            "grad b: tensor(-3.4000)\n"
          ]
        }
      ],
      "source": [
        "x = torch.tensor([1.0, 2.0, -1.0], requires_grad=True)\n",
        "w = torch.tensor([0.5, -0.3, 0.8], requires_grad=True)\n",
        "b = torch.tensor(0.2, requires_grad=True)\n",
        "\n",
        "z = torch.sum(x * w) + b\n",
        "loss = (z - 1.0) ** 2\n",
        "\n",
        "loss.backward()\n",
        "\n",
        "print(\"loss:\", loss.item())\n",
        "print(\"grad w:\", w.grad)\n",
        "print(\"grad b:\", b.grad)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe2c78a9",
      "metadata": {
        "id": "fe2c78a9"
      },
      "source": [
        "### ðŸ” Conceptual question\n",
        "\n",
        "- If `b.grad > 0`, should `b` increase or decrease after a gradient descent step?\n",
        "Explain **why** in one sentence.\n",
        "\n",
        "If b.grad > 0, b should decrease, because gradient descent subtracts the gradient to minimize the loss"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5bdee3e",
      "metadata": {
        "id": "b5bdee3e"
      },
      "source": [
        "## 5) Toy classification dataset\n",
        "\n",
        "We create a **linearly separable** dataset.\n",
        "\n",
        "Label rule:\n",
        "- class = 1 if `xâ‚ + xâ‚‚ + xâ‚ƒ > 0`\n",
        "- else class = 0\n",
        "\n",
        "This mimics a very simple classification problem.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15c8bc6a",
      "metadata": {
        "id": "15c8bc6a"
      },
      "outputs": [],
      "source": [
        "# TODO: generate a dataset\n",
        "N = 500\n",
        "\n",
        "# Features: random values\n",
        "X = torch.randn(N, 3)\n",
        "\n",
        "# Labels using the rule\n",
        "y = (X.sum(dim=1) > 0).float().unsqueeze(1)  # shape (N, 1)\n",
        "\n",
        "# TODO: split into train / validation\n",
        "split = int(0.8 * N)\n",
        "\n",
        "X_train = X[:split]\n",
        "X_val = X[split:]\n",
        "\n",
        "y_train = y[:split]\n",
        "y_val = y[split:]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "79c16fc2",
      "metadata": {
        "id": "79c16fc2"
      },
      "source": [
        "## 6) Model definition\n",
        "\n",
        "We define a small **MLP** (fully-connected network):\n",
        "\n",
        "`3 â†’ 16 â†’ 8 â†’ 1`\n",
        "\n",
        "Activation: ReLU  \n",
        "Output: raw logits (no sigmoid)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7b69f8d",
      "metadata": {
        "id": "d7b69f8d"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(3, 16),   # 3 â†’ 16\n",
        "            nn.ReLU(),         # ReLU\n",
        "            nn.Linear(16, 8),   # 16 â†’ 8\n",
        "            nn.ReLU(),         # ReLU\n",
        "            nn.Linear(8, 1)     # 8 â†’ 1 (logits)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "# TODO: create model and move it to the GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = MLP().to(device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c13b2d2",
      "metadata": {
        "id": "9c13b2d2"
      },
      "source": [
        "###  parameters\n",
        "\n",
        "1. Compute **by hand** the total number of parameters\n",
        "2. Verify your answer using PyTorch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6168e4a5",
      "metadata": {
        "id": "6168e4a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7444c06c-2fdd-4b3f-d7cc-6a1ed98c869a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "209"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "total_params\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "19f204fb",
      "metadata": {
        "id": "19f204fb"
      },
      "source": [
        "## 7) Training loop\n",
        "\n",
        "You must complete the full training loop:\n",
        "- forward pass\n",
        "- loss computation\n",
        "- backward pass\n",
        "- optimizer step\n",
        "\n",
        "Loss: `BCEWithLogitsLoss`\n",
        "Optimizer: `SGD`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d80ad2c9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d80ad2c9",
        "outputId": "32fe49b4-72da-43f0-a808-ecd38b617c6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 | loss = 0.05529891699552536\n",
            "Epoch 5 | loss = 0.05441880226135254\n",
            "Epoch 10 | loss = 0.05357513204216957\n",
            "Epoch 15 | loss = 0.05276401340961456\n",
            "Epoch 20 | loss = 0.05198308825492859\n",
            "Epoch 25 | loss = 0.05123031884431839\n",
            "Epoch 30 | loss = 0.050504233688116074\n",
            "Epoch 35 | loss = 0.049803171306848526\n",
            "Epoch 40 | loss = 0.0491260327398777\n",
            "Epoch 45 | loss = 0.04847106710076332\n"
          ]
        }
      ],
      "source": [
        "# TODO: move data to device\n",
        "X_train_d = X_train.to(device)\n",
        "y_train_d = y_train.to(device)\n",
        "X_val_d = X_val.to(device)\n",
        "y_val_d = y_val.to(device)\n",
        "\n",
        "# TODO: define loss and optimizer\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
        "\n",
        "for epoch in range(50):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # TODO: forward\n",
        "    logits = model(X_train_d)\n",
        "\n",
        "    # TODO: loss\n",
        "    loss = criterion(logits, y_train_d)\n",
        "\n",
        "    # TODO: backward\n",
        "    loss.backward()\n",
        "\n",
        "    # TODO: update\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 5 == 0:\n",
        "        print(\"Epoch\", epoch, \"| loss =\", float(loss))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c894744",
      "metadata": {
        "id": "5c894744"
      },
      "source": [
        "## 8) Evaluation\n",
        "\n",
        "1. Apply `sigmoid` to the logits\n",
        "2. Convert probabilities to predictions\n",
        "3. Compute **accuracy** on the validation set\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b10b706c",
      "metadata": {
        "id": "b10b706c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17123080-ada9-4be2-bb42-a83520cbc9e3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "#TODO: evaluation\n",
        "with torch.no_grad():\n",
        "       logits = model(X_val_d)\n",
        "       probs = torch.sigmoid(logits)\n",
        "       preds = (probs > 0.5).float()\n",
        "       accuracy = (preds == y_val_d).float().mean()\n",
        "\n",
        "accuracy = accuracy.item()\n",
        "accuracy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9698541c",
      "metadata": {
        "id": "9698541c"
      },
      "source": [
        "## 9) Reflection questions (answer inside the markdown)\n",
        "\n",
        "1. Why do we **not** apply sigmoid inside the model?\n",
        "\n",
        "We typically don't apply sigmoid directly in the model's output layer when using BCEWithLogitsLoss because this loss function combines the sigmoid activation and the binary cross-entropy loss into a single, numerically stable operation. This prevents issues like vanishing gradients that can occur when computing sigmoid and then loss separately.\n",
        "\n",
        "2. What would happen if we removed all ReLU activations?\n",
        "\n",
        "If all ReLU activations were removed, the network would become a simple linear model, regardless of the number of layers. Without non-linear activation functions, the composition of linear transformations is still a linear transformation, limiting the model's ability to learn complex, non-linear relationships in the data.\n",
        "\n",
        "3. How does this toy problem relate to image classification?\n",
        "\n",
        "This toy problem provides a simplified, foundational understanding of the core concepts used in image classification, such as defining a neural network architecture (MLP), handling data, calculating loss, and performing optimization (training loop). While image classification involves more complex inputs (pixels), specialized layers (CNNs), and larger datasets, the underlying principles of forward pass, backpropagation, and gradient-based learning remain the same.\n",
        "\n",
        "Write short answers (2â€“3 lines each).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be9f2ed3",
      "metadata": {
        "id": "be9f2ed3"
      },
      "source": [
        "## 10) Bridge to Computer Vision\n",
        "\n",
        "So far:\n",
        "- inputs = vectors of size 3\n",
        "- layers = fully-connected\n",
        "\n",
        "Next session:\n",
        "- inputs = images `(B, C, H, W)`\n",
        "- layers = convolutions\n",
        "- same training logic\n",
        "\n",
        "ðŸ‘‰ **Architecture changes, learning principles stay the same.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f479aad6",
      "metadata": {
        "id": "f479aad6"
      },
      "source": [
        "## Part II â€” Training on MNIST\n",
        "\n",
        "Check the next notebook"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}